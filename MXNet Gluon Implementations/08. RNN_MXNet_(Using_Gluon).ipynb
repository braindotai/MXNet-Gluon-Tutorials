{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN - MXNet (Using Gluon).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-IJG9NCmRBG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "cd0b052f-ab84-4e29-b21f-5811367a53be"
      },
      "source": [
        "!pip install mxnet-cu100 --pre"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet-cu100 in /usr/local/lib/python3.6/dist-packages (1.5.0b20190618)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (0.8.4)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n",
            "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (1.14.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozr4huVFmwOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "from mxnet import gluon, autograd\n",
        "from mxnet.gluon import nn, rnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DFI4FtNmwQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dictionary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = []\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.idx2word.append(word)\n",
        "            self.word2idx[word] = len(self.idx2word) - 1\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbR8YMUBmwTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Corpus(object):\n",
        "    def __init__(self, path):\n",
        "        self.dictionary = Dictionary()\n",
        "        self.train = self.tokenize(path + 'train.txt')\n",
        "        self.valid = self.tokenize(path + 'val.txt')\n",
        "        self.test = self.tokenize(path + 'test.txt')\n",
        "\n",
        "    def tokenize(self, path):\n",
        "        \"\"\"Tokenizes a text file.\"\"\"\n",
        "        print(path)\n",
        "        assert os.path.exists(path)\n",
        "        # Add words to the dictionary\n",
        "        with open(path, 'r') as f:\n",
        "            tokens = 0\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                tokens += len(words)\n",
        "                for word in words:\n",
        "                    self.dictionary.add_word(word)\n",
        "\n",
        "        # Tokenize file content\n",
        "        with open(path, 'r') as f:\n",
        "            ids = np.zeros((tokens,), dtype='int32')\n",
        "            token = 0\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                for word in words:\n",
        "                    ids[token] = self.dictionary.word2idx[word]\n",
        "                    token += 1\n",
        "\n",
        "        return mx.nd.array(ids, dtype='int32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPVVZOZZmwVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNModel(gluon.Block):\n",
        "    \"\"\"A model with an encoder, recurrent layer, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, mode, vocab_size, num_embed, num_hidden,\n",
        "                 num_layers, dropout=0.5, tie_weights=False, **kwargs):\n",
        "        super(RNNModel, self).__init__(**kwargs)\n",
        "        with self.name_scope():\n",
        "            self.drop = nn.Dropout(dropout)\n",
        "            self.encoder = nn.Embedding(vocab_size, num_embed,\n",
        "                                        weight_initializer = mx.init.Uniform(0.1))\n",
        "            if mode == 'rnn_relu':\n",
        "                self.rnn = rnn.RNN(num_hidden, num_layers, activation='relu', dropout=dropout,\n",
        "                                   input_size=num_embed)\n",
        "            elif mode == 'rnn_tanh':\n",
        "                self.rnn = rnn.RNN(num_hidden, num_layers, dropout=dropout,\n",
        "                                   input_size=num_embed)\n",
        "            elif mode == 'lstm':\n",
        "                self.rnn = rnn.LSTM(num_hidden, num_layers, dropout=dropout,\n",
        "                                    input_size=num_embed)\n",
        "            elif mode == 'gru':\n",
        "                self.rnn = rnn.GRU(num_hidden, num_layers, dropout=dropout,\n",
        "                                   input_size=num_embed)\n",
        "            else:\n",
        "                raise ValueError(\"Invalid mode %s. Options are rnn_relu, \"\n",
        "                                 \"rnn_tanh, lstm, and gru\"%mode)\n",
        "            if tie_weights:\n",
        "                self.decoder = nn.Dense(vocab_size, in_units = num_hidden,\n",
        "                                        params = self.encoder.params)\n",
        "            else:\n",
        "                self.decoder = nn.Dense(vocab_size, in_units = num_hidden)\n",
        "            self.num_hidden = num_hidden\n",
        "\n",
        "    def forward(self, inputs, hidden):\n",
        "        emb = self.drop(self.encoder(inputs))\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        output = self.drop(output)\n",
        "        decoded = self.decoder(output.reshape((-1, self.num_hidden)))\n",
        "        return decoded, hidden\n",
        "\n",
        "    def begin_state(self, *args, **kwargs):\n",
        "        return self.rnn.begin_state(*args, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfEqKkRPo3xz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca447bde-13a5-4cdb-cd62-f848abe2279a"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtcyZXIFo9p1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99534e79-91ee-4dee-e5f0-ea85985ea67b"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  test.txt  train.txt  val.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVBg7-GDmwZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args_data = '/content/'\n",
        "args_model = 'rnn_relu'\n",
        "args_emsize = 100\n",
        "args_nhid = 100\n",
        "args_nlayers = 2\n",
        "args_lr = 1.0\n",
        "args_clip = 0.2\n",
        "args_epochs = 50\n",
        "args_batch_size = 32\n",
        "args_bptt = 5\n",
        "args_dropout = 0.2\n",
        "args_tied = True\n",
        "args_cuda = 'store_true'\n",
        "args_log_interval = 500\n",
        "args_save = 'model.param'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_iGkMYxmwbB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "919d6b59-93c0-4ff6-e5fd-2630d78fc7ec"
      },
      "source": [
        "context = mx.gpu() # this notebook takes too long on cpu\n",
        "corpus = Corpus(args_data)\n",
        "\n",
        "def batchify(data, batch_size):\n",
        "    \"\"\"Reshape data into (num_example, batch_size)\"\"\"\n",
        "    nbatch = data.shape[0] // batch_size\n",
        "    data = data[:nbatch * batch_size]\n",
        "    data = data.reshape((batch_size, nbatch)).T\n",
        "    return data\n",
        "\n",
        "train_data = batchify(corpus.train, args_batch_size).as_in_context(context)\n",
        "val_data = batchify(corpus.valid, args_batch_size).as_in_context(context)\n",
        "test_data = batchify(corpus.test, args_batch_size).as_in_context(context)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/train.txt\n",
            "/content/val.txt\n",
            "/content/test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npBfhh7Omwea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ntokens = len(corpus.dictionary)\n",
        "\n",
        "model = RNNModel(args_model, ntokens, args_emsize, args_nhid,\n",
        "                       args_nlayers, args_dropout, args_tied)\n",
        "model.collect_params().initialize(mx.init.Xavier(), ctx=context)\n",
        "trainer = gluon.Trainer(model.collect_params(), 'sgd',\n",
        "                        {'learning_rate': args_lr, 'momentum': 0, 'wd': 0})\n",
        "loss = gluon.loss.SoftmaxCrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEZNJc_ImwhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(source, i):\n",
        "    seq_len = min(args_bptt, source.shape[0] - 1 - i)\n",
        "    data = source[i : i + seq_len]\n",
        "    target = source[i + 1 : i + 1 + seq_len]\n",
        "    return data, target.reshape((-1,))\n",
        "\n",
        "def detach(hidden):\n",
        "    if isinstance(hidden, (tuple, list)):\n",
        "        hidden = [i.detach() for i in hidden]\n",
        "    else:\n",
        "        hidden = hidden.detach()\n",
        "    return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF8Jz_8umwkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(data_source):\n",
        "    total_L = 0.0\n",
        "    ntotal = 0\n",
        "    hidden = model.begin_state(func = mx.nd.zeros, batch_size = args_batch_size, ctx=context)\n",
        "    for i in range(0, data_source.shape[0] - 1, args_bptt):\n",
        "        data, target = get_batch(data_source, i)\n",
        "        output, hidden = model(data, hidden)\n",
        "        L = loss(output, target)\n",
        "        total_L += mx.nd.sum(L).asscalar()\n",
        "        ntotal += L.size\n",
        "    return total_L / ntotal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik_rbSDipQm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    global arg_lr\n",
        "    best_val = float(\"Inf\")\n",
        "    for epoch in range(args_epochs):\n",
        "        total_L = 0.0\n",
        "        start_time = time.time()\n",
        "        hidden = model.begin_state(func = mx.nd.zeros, batch_size = args_batch_size, ctx = context)\n",
        "        for ibatch, i in enumerate(range(0, train_data.shape[0] - 1, args_bptt)):\n",
        "            data, target = get_batch(train_data, i)\n",
        "            hidden = detach(hidden)\n",
        "            with autograd.record():\n",
        "                output, hidden = model(data, hidden)\n",
        "                L = loss(output, target)\n",
        "                L.backward()\n",
        "\n",
        "            grads = [i.grad(context) for i in model.collect_params().values()]\n",
        "            # Here gradient is for the whole batch.\n",
        "            # So we multiply max_norm by batch_size and bptt size to balance it.\n",
        "            gluon.utils.clip_global_norm(grads, args_clip * args_bptt * args_batch_size)\n",
        "\n",
        "            trainer.step(args_batch_size)\n",
        "            total_L += mx.nd.sum(L).asscalar()\n",
        "\n",
        "            if ibatch % args_log_interval == 0 and ibatch > 0:\n",
        "                cur_L = total_L / args_bptt / args_batch_size / args_log_interval\n",
        "                print('[Epoch %d Batch %d] loss %.2f, perplexity %.2f' % (\n",
        "                    epoch + 1, ibatch, cur_L, math.exp(cur_L)))\n",
        "                total_L = 0.0\n",
        "\n",
        "        val_L = evaluate(val_data)\n",
        "\n",
        "        print('[Epoch %d] time cost %.2fs, validation loss %.2f, validation perplexity %.2f' % (\n",
        "            epoch + 1, time.time() - start_time, val_L, math.exp(val_L)))\n",
        "\n",
        "#         if val_L < best_val:\n",
        "#         best_val = val_L\n",
        "        test_L = evaluate(test_data)\n",
        "        model.save_parameters(args_save)\n",
        "        print('test loss %.2f, test perplexity %.2f' % (test_L, math.exp(test_L)))\n",
        "#         else:\n",
        "#             args_lr = args_lr * 0.25\n",
        "#             trainer._init_optimizer('sgd',\n",
        "#                                     {'learning_rate': args_lr,\n",
        "#                                      'momentum': 0,\n",
        "#                                      'wd': 0})\n",
        "#             model.load_parameters(args_save, context)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxpzisTcpQpS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1714
        },
        "outputId": "8407bfdb-b3c3-4e99-e7d9-f62c27aa90f2"
      },
      "source": [
        "train()\n",
        "model.load_parameters(args_save, context)\n",
        "test_L = evaluate(test_data)\n",
        "print('Best test loss %.2f, test perplexity %.2f'%(test_L, math.exp(test_L)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 1] time cost 0.10s, validation loss 5.43, validation perplexity 227.97\n",
            "test loss 4.72, test perplexity 111.87\n",
            "[Epoch 2] time cost 0.08s, validation loss 5.37, validation perplexity 215.28\n",
            "test loss 4.52, test perplexity 91.60\n",
            "[Epoch 3] time cost 0.07s, validation loss 5.53, validation perplexity 252.94\n",
            "test loss 4.67, test perplexity 106.71\n",
            "[Epoch 4] time cost 0.08s, validation loss 5.77, validation perplexity 320.58\n",
            "test loss 4.68, test perplexity 107.26\n",
            "[Epoch 5] time cost 0.07s, validation loss 5.65, validation perplexity 285.58\n",
            "test loss 4.53, test perplexity 92.92\n",
            "[Epoch 6] time cost 0.08s, validation loss 5.74, validation perplexity 309.67\n",
            "test loss 4.83, test perplexity 125.26\n",
            "[Epoch 7] time cost 0.08s, validation loss 5.74, validation perplexity 311.46\n",
            "test loss 4.57, test perplexity 97.00\n",
            "[Epoch 8] time cost 0.07s, validation loss 5.85, validation perplexity 347.80\n",
            "test loss 4.39, test perplexity 80.47\n",
            "[Epoch 9] time cost 0.08s, validation loss 5.79, validation perplexity 328.53\n",
            "test loss 4.44, test perplexity 84.75\n",
            "[Epoch 10] time cost 0.07s, validation loss 5.95, validation perplexity 382.32\n",
            "test loss 4.37, test perplexity 79.20\n",
            "[Epoch 11] time cost 0.07s, validation loss 6.11, validation perplexity 451.43\n",
            "test loss 4.49, test perplexity 89.24\n",
            "[Epoch 12] time cost 0.09s, validation loss 6.01, validation perplexity 408.21\n",
            "test loss 4.41, test perplexity 81.87\n",
            "[Epoch 13] time cost 0.07s, validation loss 6.02, validation perplexity 412.23\n",
            "test loss 4.40, test perplexity 81.28\n",
            "[Epoch 14] time cost 0.07s, validation loss 6.08, validation perplexity 435.92\n",
            "test loss 4.46, test perplexity 86.39\n",
            "[Epoch 15] time cost 0.08s, validation loss 5.91, validation perplexity 367.83\n",
            "test loss 4.38, test perplexity 80.17\n",
            "[Epoch 16] time cost 0.07s, validation loss 6.56, validation perplexity 704.91\n",
            "test loss 4.83, test perplexity 125.13\n",
            "[Epoch 17] time cost 0.08s, validation loss 6.33, validation perplexity 559.51\n",
            "test loss 4.18, test perplexity 65.42\n",
            "[Epoch 18] time cost 0.08s, validation loss 5.81, validation perplexity 332.14\n",
            "test loss 4.15, test perplexity 63.48\n",
            "[Epoch 19] time cost 0.08s, validation loss 6.68, validation perplexity 797.35\n",
            "test loss 4.14, test perplexity 62.70\n",
            "[Epoch 20] time cost 0.08s, validation loss 6.27, validation perplexity 530.00\n",
            "test loss 4.22, test perplexity 68.31\n",
            "[Epoch 21] time cost 0.08s, validation loss 6.57, validation perplexity 716.21\n",
            "test loss 4.57, test perplexity 96.13\n",
            "[Epoch 22] time cost 0.08s, validation loss 6.23, validation perplexity 506.21\n",
            "test loss 4.45, test perplexity 85.41\n",
            "[Epoch 23] time cost 0.10s, validation loss 6.95, validation perplexity 1042.81\n",
            "test loss 4.32, test perplexity 75.55\n",
            "[Epoch 24] time cost 0.08s, validation loss 5.97, validation perplexity 392.45\n",
            "test loss 3.91, test perplexity 49.92\n",
            "[Epoch 25] time cost 0.09s, validation loss 6.58, validation perplexity 720.52\n",
            "test loss 3.91, test perplexity 50.03\n",
            "[Epoch 26] time cost 0.09s, validation loss 6.34, validation perplexity 567.22\n",
            "test loss 4.00, test perplexity 54.58\n",
            "[Epoch 27] time cost 0.09s, validation loss 7.01, validation perplexity 1109.71\n",
            "test loss 4.19, test perplexity 65.81\n",
            "[Epoch 28] time cost 0.08s, validation loss 6.24, validation perplexity 510.40\n",
            "test loss 3.84, test perplexity 46.54\n",
            "[Epoch 29] time cost 0.08s, validation loss 6.94, validation perplexity 1033.42\n",
            "test loss 4.21, test perplexity 67.10\n",
            "[Epoch 30] time cost 0.08s, validation loss 6.36, validation perplexity 580.03\n",
            "test loss 3.73, test perplexity 41.67\n",
            "[Epoch 31] time cost 0.08s, validation loss 6.47, validation perplexity 648.53\n",
            "test loss 3.71, test perplexity 40.70\n",
            "[Epoch 32] time cost 0.08s, validation loss 6.63, validation perplexity 759.76\n",
            "test loss 3.72, test perplexity 41.38\n",
            "[Epoch 33] time cost 0.11s, validation loss 7.49, validation perplexity 1785.28\n",
            "test loss 3.84, test perplexity 46.54\n",
            "[Epoch 34] time cost 0.08s, validation loss 6.86, validation perplexity 949.81\n",
            "test loss 3.66, test perplexity 38.81\n",
            "[Epoch 35] time cost 0.08s, validation loss 7.10, validation perplexity 1217.06\n",
            "test loss 3.91, test perplexity 49.82\n",
            "[Epoch 36] time cost 0.08s, validation loss 6.81, validation perplexity 903.53\n",
            "test loss 3.81, test perplexity 45.10\n",
            "[Epoch 37] time cost 0.08s, validation loss 7.62, validation perplexity 2037.35\n",
            "test loss 4.01, test perplexity 55.29\n",
            "[Epoch 38] time cost 0.09s, validation loss 7.13, validation perplexity 1250.98\n",
            "test loss 3.72, test perplexity 41.46\n",
            "[Epoch 39] time cost 0.08s, validation loss 6.58, validation perplexity 719.28\n",
            "test loss 3.59, test perplexity 36.20\n",
            "[Epoch 40] time cost 0.09s, validation loss 7.65, validation perplexity 2105.85\n",
            "test loss 3.79, test perplexity 44.38\n",
            "[Epoch 41] time cost 0.08s, validation loss 6.46, validation perplexity 636.04\n",
            "test loss 3.68, test perplexity 39.68\n",
            "[Epoch 42] time cost 0.09s, validation loss 7.32, validation perplexity 1510.10\n",
            "test loss 3.69, test perplexity 40.05\n",
            "[Epoch 43] time cost 0.08s, validation loss 6.76, validation perplexity 865.83\n",
            "test loss 3.52, test perplexity 33.89\n",
            "[Epoch 44] time cost 0.09s, validation loss 7.00, validation perplexity 1092.18\n",
            "test loss 3.56, test perplexity 35.08\n",
            "[Epoch 45] time cost 0.08s, validation loss 7.51, validation perplexity 1817.33\n",
            "test loss 3.69, test perplexity 40.17\n",
            "[Epoch 46] time cost 0.08s, validation loss 7.54, validation perplexity 1888.74\n",
            "test loss 3.96, test perplexity 52.27\n",
            "[Epoch 47] time cost 0.08s, validation loss 7.72, validation perplexity 2244.97\n",
            "test loss 3.58, test perplexity 35.94\n",
            "[Epoch 48] time cost 0.08s, validation loss 7.06, validation perplexity 1160.85\n",
            "test loss 3.53, test perplexity 34.15\n",
            "[Epoch 49] time cost 0.09s, validation loss 7.63, validation perplexity 2068.96\n",
            "test loss 3.65, test perplexity 38.38\n",
            "[Epoch 50] time cost 0.08s, validation loss 6.75, validation perplexity 855.50\n",
            "test loss 3.40, test perplexity 29.92\n",
            "Best test loss 3.40, test perplexity 29.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWvEY-TepQtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}